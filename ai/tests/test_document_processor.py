import asyncio
import sys
import os
import tempfile
import time
import shutil

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.document_processor import DocumentProcessorOrchestrator

class TestDocumentProcessor:
    def __init__(self):
        self.test_dir = None
        self.processor = None
    
    async def setup(self):
        """Set up test environment"""
        print("ğŸ§ª Setting up test environment...")
        
        # Create temporary directory
        self.test_dir = tempfile.mkdtemp(prefix="test_docs_")
        print(f"ğŸ“ Test directory: {self.test_dir}")
        
        # Create test files
        await self._create_test_files()
        
        try:
            # Initialize processor with test directory
            self.processor = DocumentProcessorOrchestrator(persist_dir="./test_chroma_db")
            print("âœ… Test environment ready")
        except Exception as e:
            print(f"âŒ Failed to initialize processor: {e}")
            # Clean up and re-raise
            if os.path.exists("./test_chroma_db"):
                shutil.rmtree("./test_chroma_db", ignore_errors=True)
            raise
    
    async def _create_test_files(self):
        """Create various test files"""
        # Test TXT file
        txt_content = """This is a test document about sales.
Total Revenue: â‚±10,000
Products sold: 50 units
Customer satisfaction: 95%"""
        
        with open(os.path.join(self.test_dir, "sales.txt"), "w", encoding="utf-8") as f:
            f.write(txt_content)
        
        # Test large TXT file (to test chunking)
        large_content = "This is a large document. " * 1000  # ~25KB
        with open(os.path.join(self.test_dir, "large_doc.txt"), "w", encoding="utf-8") as f:
            f.write(large_content)
        
        # Test unsupported file
        with open(os.path.join(self.test_dir, "image.jpg"), "w") as f:
            f.write("fake image content")
        
        print(f"ï¿½ï¿½ Created test files in {self.test_dir}")
    
    async def test_initialization(self):
        """Test document processor initialization"""
        print("\nğŸ” Testing initialization...")
        
        try:
            await self.processor.initialize_from_directory(self.test_dir)
            
            # Check stats
            stats = self.processor.get_stats()
            print(f"ğŸ“Š Index stats: {stats}")
            
            # Should have 2 supported files (txt files)
            assert stats["total_files"] == 2, f"Expected 2 files, got {stats['total_files']}"
            
            # Check for files using full paths
            sales_file = os.path.join(self.test_dir, "sales.txt")
            large_file = os.path.join(self.test_dir, "large_doc.txt")
            
            assert sales_file in stats["indexed_files"], f"sales.txt not found in {stats['indexed_files']}"
            assert large_file in stats["indexed_files"], f"large_doc.txt not found in {stats['indexed_files']}"
            
            print("âœ… Initialization test passed")
            return True
            
        except Exception as e:
            print(f"âŒ Initialization test failed: {e}")
            return False
    
    async def test_file_validation(self):
        """Test file validation logic"""
        print("\nğŸ” Testing file validation...")
        
        # Test valid file
        valid_file = os.path.join(self.test_dir, "sales.txt")
        is_valid, error = self.processor._validate_file(valid_file)
        assert is_valid, f"Valid file should pass validation: {error}"
        
        # Test unsupported file
        unsupported_file = os.path.join(self.test_dir, "image.jpg")
        is_valid, error = self.processor._validate_file(unsupported_file)
        assert not is_valid, "Unsupported file should fail validation"
        
        # Test non-existent file
        non_existent = os.path.join(self.test_dir, "nonexistent.txt")
        is_valid, error = self.processor._validate_file(non_existent)
        assert not is_valid, "Non-existent file should fail validation"
        
        print("âœ… File validation test passed")
        return True
    
    async def test_hash_detection(self):
        """Test file hash change detection"""
        print("\nğŸ” Testing hash detection...")
        
        file_path = os.path.join(self.test_dir, "sales.txt")
        
        # Get initial hash
        initial_hash = self.processor._calculate_file_hash(file_path)
        print(f"ğŸ“ Initial hash: {initial_hash[:10]}...")
        
        # Modify file
        with open(file_path, "a", encoding="utf-8") as f:
            f.write("\nNew line added for testing.")
        
        # Get new hash
        new_hash = self.processor._calculate_file_hash(file_path)
        print(f"ğŸ“ New hash: {new_hash[:10]}...")
        
        # Hashes should be different
        assert initial_hash != new_hash, "Hashes should be different after file modification"
        
        print("âœ… Hash detection test passed")
        return True
    
    async def test_document_update(self):
        """Test document update functionality"""
        print("\nğŸ” Testing document update...")
        
        file_path = os.path.join(self.test_dir, "sales.txt")
        
        # Get initial document count
        initial_stats = self.processor.get_stats()
        initial_count = initial_stats["total_chunks"]
        
        # Update the document
        await self.processor.add_document(file_path)
        
        # Get updated stats
        updated_stats = self.processor.get_stats()
        updated_count = updated_stats["total_chunks"]
        
        # Should have same or more chunks (depending on chunking)
        assert updated_count >= initial_count, "Document count should not decrease after update"
        
        print("âœ… Document update test passed")
        return True
    
    async def test_document_removal(self):
        """Test document removal functionality"""
        print("\nğŸ” Testing document removal...")
        
        file_path = os.path.join(self.test_dir, "sales.txt")
        
        # First, add a document to ensure there's something to remove
        await self.processor.add_document(file_path)
        
        # Get initial document count
        initial_stats = self.processor.get_stats()
        initial_count = initial_stats["total_chunks"]
        
        # Remove the document
        await self.processor.remove_document(file_path)
        
        # Get updated stats
        updated_stats = self.processor.get_stats()
        updated_count = updated_stats["total_chunks"]
        
        # Should have fewer documents
        assert updated_count < initial_count, "Document count should decrease after removal"
        
        # File should not be in indexed files
        assert file_path not in updated_stats["indexed_files"], "File should be removed from indexed files"
        
        print("âœ… Document removal test passed")
        return True
    
    async def test_query_functionality(self):
        """Test query functionality"""
        print("\nğŸ” Testing query functionality...")
        
        try:
            # First ensure we have documents indexed
            if self.processor.get_stats()["total_files"] == 0:
                print("âš ï¸ No documents indexed, skipping query test")
                return True
            
            # Test a simple query
            response = await self.processor.query("What is the total revenue?")
            
            print(f"ğŸ¤– Query response: {response.message}")
            print(f"ğŸ“‹ Sources found: {len(response.sources)}")
            print(f"â±ï¸ Response time: {response.response_time}s")
            
            # Should have a response
            assert response.message, "Query should return a response"
            assert hasattr(response, 'sources'), "Response should have sources"
            assert hasattr(response, 'response_time'), "Response should have response_time"
            
            # Should have sources if documents are indexed
            if self.processor.get_stats()["total_files"] > 0:
                assert len(response.sources) > 0, "Query should return sources when documents are indexed"
            
            print("âœ… Query functionality test passed")
            return True
            
        except Exception as e:
            print(f"âŒ Query functionality test failed: {e}")
            # Don't fail the test if Ollama is not running
            if "connection" in str(e).lower() or "ollama" in str(e).lower():
                print("âš ï¸ Ollama not running - this is expected in test environment")
                return True
            return False
    
    async def test_llm_integration(self):
        """Test LLM integration (if Ollama is available)"""
        print("\nğŸ” Testing LLM integration...")
        
        try:
            # Test with a simple context
            context = "Total Revenue: â‚±10,000\nProducts sold: 50 units"
            response = await self.processor._generate_llm_response("What is the revenue?", context)
            
            print(f"ğŸ¤– LLM response: {response[:100]}...")
            
            # Should have a response
            assert response, "LLM should return a response"
            assert len(response) > 10, "Response should be meaningful"
            
            print("âœ… LLM integration test passed")
            return True
            
        except Exception as e:
            print(f"âš ï¸ LLM integration test skipped (Ollama not available): {e}")
            return True  # Don't fail if Ollama is not running
    
    async def test_chunking(self):
        """Test text chunking functionality"""
        print("\n Testing text chunking...")
        
        # Test with small text (should not chunk)
        small_text = "This is a small text."
        chunks = self.processor._create_chunks(small_text, "test.txt")
        assert len(chunks) == 1, "Small text should not be chunked"
        
        # Test with large text (should chunk)
        large_text = "This is a large text. " * 500  # ~10KB
        chunks = self.processor._create_chunks(large_text, "test.txt")
        assert len(chunks) > 1, "Large text should be chunked"
        
        # Check chunk metadata
        for i, chunk in enumerate(chunks):
            assert hasattr(chunk, 'text'), "Chunk should have text"
            assert hasattr(chunk, 'chunk_id'), "Chunk should have chunk_id"
            assert hasattr(chunk, 'total_chunks'), "Chunk should have total_chunks"
            assert chunk.chunk_id == i, "Chunk IDs should be sequential"
        
        print(f"âœ… Chunking test passed - {len(chunks)} chunks created")
        return True
    
    async def test_error_handling(self):
        """Test error handling"""
        print("\nğŸ” Testing error handling...")
        
        # Test with non-existent file
        try:
            await self.processor.add_document("non_existent_file.txt")
            print("âš ï¸ Should have failed for non-existent file")
        except Exception as e:
            print(f"âœ… Correctly handled non-existent file: {e}")
        
        # Test with unsupported file type
        unsupported_file = os.path.join(self.test_dir, "image.jpg")
        try:
            await self.processor.add_document(unsupported_file)
            print("âš ï¸ Should have failed for unsupported file type")
        except Exception as e:
            print(f"âœ… Correctly handled unsupported file type: {e}")
        
        print("âœ… Error handling test passed")
        return True
    
    async def cleanup(self):
        """Clean up test environment"""
        print("\nğŸ§¹ Cleaning up test environment...")
        
        # Clean up document processor
        if self.processor:
            await self.processor.cleanup()
            print("ğŸ§¹ Cleaned up document processor")
        
        if self.test_dir and os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
            print(f"ğŸ—‘ï¸ Removed test directory: {self.test_dir}")
        
        # Clean up test ChromaDB with better error handling
        if os.path.exists("./test_chroma_db"):
            try:
                # Give ChromaDB time to close files
                await asyncio.sleep(1)
                shutil.rmtree("./test_chroma_db", ignore_errors=True)
                print("ğŸ—‘ï¸ Removed test ChromaDB")
            except Exception as e:
                print(f"âš ï¸ Could not remove test ChromaDB (this is normal): {e}")
        
        print("âœ… Cleanup completed")

async def run_all_tests():
    """Run all document processor tests"""
    print("ğŸš€ Starting Document Processor Tests...")
    
    tester = TestDocumentProcessor()
    
    try:
        # Setup
        await tester.setup()
        
        # Run tests
        tests = [
            ("Initialization", tester.test_initialization),
            ("File Validation", tester.test_file_validation),
            ("Hash Detection", tester.test_hash_detection),
            ("Document Update", tester.test_document_update),
            ("Document Removal", tester.test_document_removal),
            ("Query Functionality", tester.test_query_functionality),
            ("LLM Integration", tester.test_llm_integration),  # Add this
            ("Chunking", tester.test_chunking),
            ("Error Handling", tester.test_error_handling),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            print(f"\n{'='*50}")
            print(f"ğŸ§ª Running: {test_name}")
            print(f"{'='*50}")
            
            try:
                result = await test_func()
                if result:
                    passed += 1
                    print(f"âœ… {test_name}: PASSED")
                else:
                    print(f"âŒ {test_name}: FAILED")
            except Exception as e:
                print(f"âŒ {test_name}: ERROR - {e}")
        
        # Summary
        print(f"\n{'='*50}")
        print(f"ğŸ“Š TEST SUMMARY")
        print(f"{'='*50}")
        print(f"âœ… Passed: {passed}/{total}")
        print(f"âŒ Failed: {total - passed}/{total}")
        print(f"ğŸ“ˆ Success Rate: {(passed/total)*100:.1f}%")
        
        if passed == total:
            print("ğŸ‰ All tests passed!")
        else:
            print("âš ï¸ Some tests failed. Check the output above.")
        
    except Exception as e:
        print(f"âŒ Test suite error: {e}")
    
    finally:
        # Cleanup
        await tester.cleanup()

if __name__ == "__main__":
    asyncio.run(run_all_tests())